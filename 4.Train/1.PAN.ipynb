{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ad79743-89d9-4c44-8117-d93c7e03f966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import argparse\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "print(tf.__version__)\n",
    "\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9db804b-a9f7-4281-89ee-50e05ce1cabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making results reproduceable\n",
    "RANDOM_SEED=42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aa4f6a5-03e1-42fa-bcd0-3cf288ec7872",
   "metadata": {},
   "outputs": [],
   "source": [
    "path =  \"../data/\"\n",
    "dataset = \"cb12/\"\n",
    "\n",
    "raw_path = path + dataset + \"raw/\" \n",
    "interim_path = path + dataset + \"interim/\"\n",
    "processed_path = path + dataset + \"processed/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf13fee6-e564-43a4-9bbf-93e0661df07f",
   "metadata": {},
   "source": [
    "# Step 1: Prepare job data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23a47d8a-bae9-4af1-9f2d-cab4ae1f4056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import serialize, deserialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a1967f2-4c64-49c8-a22b-9c8f5f60f025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading job label encoders, job metadata and embeddings from ../data/cb12/pickles/job_14d_30_metadata_and_embeddings_d2v.pickle\n"
     ]
    }
   ],
   "source": [
    "def load_job_metadata_and_embeddings(input_job_metadata_and_embeddings_path):\n",
    "    print('Loading job label encoders, job metadata and embeddings from {}'.format(input_job_metadata_and_embeddings_path))\n",
    "    job_label_encoders, job_metadata_df, job_content_embeddings = deserialize(input_job_metadata_and_embeddings_path)\n",
    "    return job_label_encoders, job_metadata_df, job_content_embeddings\n",
    "\n",
    "job_label_encoders, job_metadata_df, job_content_embeddings = load_job_metadata_and_embeddings('../data/cb12/pickles/job_14d_30_metadata_and_embeddings_d2v.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fe89580-45bc-4337-861b-23f2ab590167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207972, 20)\n"
     ]
    }
   ],
   "source": [
    "job_metadata_df = job_metadata_df.drop(columns=['JobCity','JobState', 'JobCountry'])\n",
    "job_metadata_df.rename(columns={\"JobCity_encoded\": \"JobCity\", \"JobState_encoded\": \"JobState\", \"JobCountry_encoded\": \"JobCountry\"}, inplace = True)\n",
    "print(job_metadata_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "932e5d77-67cc-44e6-abd5-c59add2a3e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply l2-norm by sample\n",
    "l2_normalizer_by_sample = Normalizer(norm='l2')\n",
    "job_content_embeddings = l2_normalizer_by_sample.fit_transform(job_content_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9baae91-47f7-4075-af94-366f00cf7cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rescaling content features  \n",
    "content_embedding_scale_factor = 1.0\n",
    "job_content_embeddings = job_content_embeddings * content_embedding_scale_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d2ac371-4f48-48bb-a35b-f3d8d152fc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Features: {'JobID': {'type': 'categorical', 'dtype': 'int', 'cardinality': 207973}, 'StartDate': {'type': 'numerical', 'dtype': 'int'}, 'EndDate': {'type': 'numerical', 'dtype': 'int'}, 'JobCity': {'type': 'categorical', 'dtype': 'int', 'cardinality': 8227}, 'JobState': {'type': 'categorical', 'dtype': 'int', 'cardinality': 123}, 'JobCountry': {'type': 'categorical', 'dtype': 'int', 'cardinality': 34}}\n"
     ]
    }
   ],
   "source": [
    "from feature_helper import get_job_features_config\n",
    "\n",
    "def process_job_metadata(job_metadata_df, job_features_config):\n",
    "    job_metadata = {}\n",
    "    for feature_name in job_features_config:\n",
    "        job_metadata[feature_name] = job_metadata_df[feature_name].values\n",
    "        #Appending a row in the first position to correspond to the <PAD> article #\n",
    "        # (so that it correspond to content_article_embeddings_matrix.shape[0])\n",
    "        job_metadata[feature_name] = np.hstack([[0], job_metadata[feature_name]])\n",
    "    return job_metadata\n",
    "\n",
    "\n",
    "job_features_config = get_job_features_config(job_label_encoders)\n",
    "job_metadata = process_job_metadata(job_metadata_df, job_features_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a7716c-d26f-4b43-b91c-588fc3da6764",
   "metadata": {},
   "source": [
    "# Step 2: Prepare user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02a40bf7-e383-4308-86e0-bf18081b6dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading user label encoders and user metadata from ../data/cb12/pickles/user_14d_30_metadata.pickle\n"
     ]
    }
   ],
   "source": [
    "def load_user_metadata(input_user_metadata_path):\n",
    "    print('Loading user label encoders and user metadata from {}'.format(input_user_metadata_path))\n",
    "    user_label_encoders, user_metadata_df = deserialize(input_user_metadata_path)\n",
    "    return user_label_encoders, user_metadata_df\n",
    "\n",
    "\n",
    "def process_user_metadata(user_metadata_df, user_features_config):\n",
    "    user_metadata = {}\n",
    "    for feature_name in user_features_config:\n",
    "        user_metadata[feature_name] = user_metadata_df[feature_name + '_encoded'].values\n",
    "        #Appending a row in the first position to correspond to the <PAD> article #\n",
    "        # (so that it correspond to content_article_embeddings_matrix.shape[0])\n",
    "        user_metadata[feature_name] = np.hstack([[0], user_metadata[feature_name]])\n",
    "    return user_metadata\n",
    "\n",
    "\n",
    "user_label_encoders, user_metadata_df = load_user_metadata('../data/cb12/pickles/user_14d_30_metadata.pickle')\n",
    "user_metadata = process_user_metadata(user_metadata_df, user_label_encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d42a0bc-0f7f-41ea-b384-e31ac4b7ae9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Features: {'UserID': {'type': 'categorical', 'dtype': 'int', 'cardinality': 111786}, 'UserCity': {'type': 'categorical', 'dtype': 'int', 'cardinality': 8227}, 'UserState': {'type': 'categorical', 'dtype': 'int', 'cardinality': 123}, 'UserCountry': {'type': 'categorical', 'dtype': 'int', 'cardinality': 34}, 'UserDegree': {'type': 'categorical', 'dtype': 'int', 'cardinality': 8}, 'UserMajor': {'type': 'categorical', 'dtype': 'int', 'cardinality': 21225}}\n"
     ]
    }
   ],
   "source": [
    "from feature_helper import get_user_features_config\n",
    "\n",
    "user_features_config = get_user_features_config(user_label_encoders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ca06e4-6900-495e-85a9-e82c57fe0565",
   "metadata": {},
   "source": [
    "# Step 3: Prepare session config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52819a62-c568-473f-b83e-7effda7aa50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_helper import get_session_features_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68894e90-8817-41a4-b031-7f07e745b8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session Features: {'single_features': {'SessionID': {'type': 'numerical', 'dtype': 'int'}, 'UserID': {'type': 'numerical', 'dtype': 'int'}, 'SessionSize': {'type': 'numerical', 'dtype': 'int'}, 'SessionStart': {'type': 'numerical', 'dtype': 'int'}}, 'sequence_features': {'ApplicationDate': {'type': 'numerical', 'dtype': 'int'}, 'Job_clicked': {'type': 'categorical', 'dtype': 'int'}, 'JobCity': {'type': 'categorical', 'dtype': 'int', 'cardinality': 8227}, 'JobState': {'type': 'categorical', 'dtype': 'int', 'cardinality': 123}, 'JobCountry': {'type': 'categorical', 'dtype': 'int', 'cardinality': 34}, 'UserCity': {'type': 'categorical', 'dtype': 'int', 'cardinality': 8227}, 'UserState': {'type': 'categorical', 'dtype': 'int', 'cardinality': 123}, 'UserCountry': {'type': 'categorical', 'dtype': 'int', 'cardinality': 34}, 'UserDegree': {'type': 'categorical', 'dtype': 'int', 'cardinality': 8}, 'UserMajor': {'type': 'categorical', 'dtype': 'int', 'cardinality': 21225}}}\n"
     ]
    }
   ],
   "source": [
    "session_features_config = get_session_features_config(job_label_encoders, user_label_encoders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae1c60a-a697-48b2-a09c-4a22fe58329f",
   "metadata": {},
   "source": [
    "# Step 4: Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdd0b57-fd39-4c9b-814d-8cd6ae70ce4c",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43037a52-42e9-4f54-950a-6868f99653e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from PAN_model_improved_sampling import PAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5aa2a2-b5ae-4f5a-a516-bd48e709c5c6",
   "metadata": {},
   "source": [
    "### ClickedJobsState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbcdc3c1-9b20-463d-96b1-aa4a0f62b6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clicked_job_state import ClickedJobsState"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96f1b09-287f-4ab2-bb90-2e3e0c81db7a",
   "metadata": {},
   "source": [
    "### Hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "394a1e4f-dc83-4c75-9969-e37eb47d5975",
   "metadata": {},
   "outputs": [],
   "source": [
    "from job_state_hook import JobsStateUpdaterHook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4283d51-135c-4e64-aef9-e3697f5c3550",
   "metadata": {},
   "source": [
    "# Step 5: Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24de6bbd-d0c3-4da0-8034-c81cb5b56de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from data_helper import prepare_dataset_iterator\n",
    "import multiprocessing\n",
    "from utils import merge_two_dicts, get_tf_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e79c03be-a8ac-49f4-9b15-274764087773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from data_helper import prepare_dataset_iterator\n",
    "import multiprocessing\n",
    "from utils import merge_two_dicts, get_tf_dtype\n",
    "\n",
    "\n",
    "def expand_single_features(x, features_to_expand):\n",
    "    \"\"\"\n",
    "    Hack. Because padded_batch doesn't play nice with scalars, so we expand the scalar to a vector of length 1\n",
    "    \"\"\"\n",
    "    for feature_key in features_to_expand:\n",
    "        x[feature_key] = tf.expand_dims(tf.convert_to_tensor(x[feature_key]), 0)\n",
    "    return x\n",
    "\n",
    "\n",
    "def parse_sequence_example(example, features_config, truncate_sequence_length=20):\n",
    "    # Define how to parse the example\n",
    "    \n",
    "    context_features = {}\n",
    "    features_config_single = features_config['single_features']\n",
    "    for feature_name in features_config_single:        \n",
    "        context_features[feature_name] = tf.FixedLenFeature([], dtype=get_tf_dtype(features_config_single[feature_name]['dtype']))\n",
    "    \n",
    "    sequence_features = {}\n",
    "    features_config_sequence = features_config['sequence_features']\n",
    "    for feature_name in features_config_sequence: \n",
    "        sequence_features[feature_name] = tf.FixedLenSequenceFeature(shape=[], dtype=get_tf_dtype(features_config_sequence[feature_name]['dtype']))\n",
    "        \n",
    "    context_parsed, sequence_parsed = tf.parse_single_sequence_example(\n",
    "        example, \n",
    "        sequence_features=sequence_features,\n",
    "        context_features=context_features,\n",
    "        example_name=\"example\"\n",
    "    )\n",
    "    \n",
    "    #Truncate long sessions to a limit\n",
    "    context_parsed['SessionSize'] = tf.minimum(context_parsed['SessionSize'], truncate_sequence_length)\n",
    "    \n",
    "    for feature_name in sequence_parsed:\n",
    "        sequence_parsed[feature_name] = sequence_parsed[feature_name][:truncate_sequence_length] \n",
    "    \n",
    "    #Ignoring first click from labels\n",
    "    sequence_parsed['label_next_job'] = sequence_parsed['Job_clicked'][1:]    \n",
    "    #Making it easy to retrieve the last label\n",
    "    sequence_parsed['label_last_job'] = sequence_parsed['Job_clicked'][-1:]\n",
    "    \n",
    "    #Ignoring last clicked item from input    \n",
    "    for feature_key in sequence_features:\n",
    "        if feature_key not in ['label_next_job', 'label_last_job']:\n",
    "            sequence_parsed[feature_key] = sequence_parsed[feature_key][:-1]\n",
    "    \n",
    "    merged_features = merge_two_dicts(context_parsed, sequence_parsed)\n",
    "    \n",
    "    #In order the pad the dataset, I had to use this hack to expand scalars to vectors.\n",
    "    merged_expanded_features = expand_single_features(merged_features, features_to_expand=list(features_config['single_features'].keys()))\n",
    "    return merged_expanded_features\n",
    "\n",
    "\n",
    "def expand_to_vector_if_scalar(tensor):\n",
    "    return tf.cond(tf.logical_and(tf.equal(tf.size(tensor), tf.constant(1)),tf.equal(tf.rank(tensor), tf.constant(0))), lambda: tf.expand_dims(tensor, 0), lambda: tensor)\n",
    "\n",
    "\n",
    "\n",
    "def deflate_single_features(x, expanded_features):\n",
    "    \"\"\"\n",
    "    Undo Hack. We undo the expansion we did in expand and make sure that vector has rank 2 (adds one dimension if this batch size == 1)\n",
    "    \"\"\"\n",
    "    for feature_key in expanded_features:\n",
    "        if feature_key != 'UserID':\n",
    "            x[feature_key] = expand_to_vector_if_scalar(tf.squeeze(x[feature_key]))\n",
    "    return x\n",
    "\n",
    "    \n",
    "def deflate_and_split_features_label(x, expanded_features): \n",
    "    #Undo that hack required for padding \n",
    "    x = deflate_single_features(x, expanded_features)\n",
    "    labels = {\n",
    "        'label_next_job': x['label_next_job'],\n",
    "        'label_last_job': x['label_last_job']\n",
    "    }\n",
    "    del x['label_next_job']\n",
    "    del x['label_last_job']\n",
    "    \n",
    "    #Returning features and label separatelly\n",
    "    return(x, labels)\n",
    "\n",
    "def make_dataset(path, features_config, batch_size=128, num_map_threads=None, truncate_sequence_length=20):\n",
    "    def get_features_shapes(features_config):\n",
    "        features_shapes = {}\n",
    "        \n",
    "        for feature_name in features_config['single_features']:        \n",
    "            features_shapes[feature_name] = 1\n",
    "        \n",
    "        for feature_name in features_config['sequence_features']:        \n",
    "            features_shapes[feature_name] = tf.TensorShape([None])\n",
    "        \n",
    "        features_shapes['label_next_job'] = tf.TensorShape([None])\n",
    "        features_shapes['label_last_job'] = tf.TensorShape([None])\n",
    "        \n",
    "        return features_shapes\n",
    "    \n",
    "    if not num_map_threads:\n",
    "        num_map_threads = multiprocessing.cpu_count()\n",
    "        print('Using {} threads for parallel map'.format(num_map_threads))\n",
    "    \n",
    "    # Read a tf record file. This makes a dataset of raw TFRecords\n",
    "    dataset = tf.data.TFRecordDataset(path, compression_type='GZIP')\n",
    "    # Apply/map the parse function to every record. Now the dataset is a bunch of dictionaries of Tensors\n",
    "    dataset =  dataset.map(lambda x: parse_sequence_example(x, features_config, truncate_sequence_length=truncate_sequence_length), num_parallel_calls=num_map_threads)\n",
    "    \n",
    "    #Batch the dataset so that we get batch_size examples in each batch.\n",
    "    #Remember each item in the dataset is a dict of tensors, we need to specify padding for each tensor separately    \n",
    "    features_shapes = get_features_shapes(features_config)\n",
    "    dataset = dataset.padded_batch(batch_size, padded_shapes=features_shapes)\n",
    "    \n",
    "    #Splitting features and label\n",
    "    expanded_features=list(features_config['single_features'].keys())\n",
    "    dataset = dataset.map(lambda x: deflate_and_split_features_label(x, expanded_features), num_parallel_calls=num_map_threads)\n",
    "    \n",
    "    #Pre-fetches one batch ahead\n",
    "    dataset = dataset.prefetch(1)\n",
    "    return dataset\n",
    "\n",
    "    \n",
    "    \n",
    "def prepare_dataset_iterator(path, features_config, batch_size=128, truncate_session_length=10):\n",
    "    with tf.device('/cpu:0'):\n",
    "        # Make a dataset \n",
    "        ds = make_dataset(path, features_config, batch_size=batch_size, truncate_sequence_length=truncate_session_length)    \n",
    "        # Define an abstract iterator that has the shape and type of our datasets\n",
    "        iterator = ds.make_one_shot_iterator()\n",
    "        \n",
    "        # This is an op that gets the next element from the iterator\n",
    "        next_element = iterator.get_next()\n",
    "        \n",
    "        return next_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4936e28-5014-4d76-acd3-1d7b6c4e0a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training parameters\n",
    "batch_size = 256\n",
    "learning_rate = 0.001\n",
    "dropout_keep_prob = 0.8\n",
    "reg_l2 = 0.0001\n",
    "softmax_temperature = 1.0\n",
    "\n",
    "pretrained_job_embedding_size = 300\n",
    "max_cardinality_for_ohe = 10\n",
    "truncate_session_length = 10\n",
    "\n",
    "### Recent applications buffer\n",
    "# Maximum size of recent clicks buffer\n",
    "recent_clicks_buffer_max_size = 1000\n",
    "recent_clicks_for_normalization = 1000\n",
    "\n",
    "### Negative samples\n",
    "train_total_negative_samples = 15\n",
    "# Training Negative samples from recent clicks buffer\n",
    "train_negative_samples_from_buffer = 100\n",
    "\n",
    "eval_total_negative_samples = 50\n",
    "# Eval. Negative samples from recent clicks buffer\n",
    "eval_negative_samples_from_buffer = 200\n",
    "\n",
    "### RNN parameters\n",
    "rnn_num_layers = 1\n",
    "rnn_units = 256\n",
    "\n",
    "### Evaluation\n",
    "eval_metrics_top_n = 5\n",
    "\n",
    "### Others\n",
    "save_histograms = False\n",
    "\n",
    "eval_metrics_by_session_position = False\n",
    "eval_negative_sample_relevance = 1.0\n",
    "save_eval_sessions_negative_samples = True\n",
    "save_eval_sessions_recommendations = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9f5de38-8d0e-46dc-a521-e735b2fe4e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global vars updated by the Estimator Hook\n",
    "clicked_jobs_state = None\n",
    "eval_sessions_metrics_log = [] \n",
    "sessions_negative_jobs_log = [] if save_eval_sessions_negative_samples else None\n",
    "sessions_model_recommendations_log = [] if save_eval_sessions_recommendations else None\n",
    "global_eval_hour_id = 0\n",
    "\n",
    "clicked_jobs_state = ClickedJobsState(recent_clicks_buffer_max_size, \n",
    "                                      recent_clicks_for_normalization, \n",
    "                                      job_content_embeddings.shape[0])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7a36cdf-3d68-4992-b24f-69f80c38cb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./tmp/30_improved_sampling/PAN_30_256_15_50_0.001_0.0001_1000_100_200\n",
      "INFO:tensorflow:Using config: {'_model_dir': './tmp/30_improved_sampling/PAN_30_256_15_50_0.001_0.0001_1000_100_200', '_tf_random_seed': 42, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 1200, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fddcd554790>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "Using 8 threads for parallel map\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/envs/py3.7/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/envs/py3.7/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenSequenceFeature is deprecated. Please use tf.io.FixedLenSequenceFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/envs/py3.7/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_sequence_example is deprecated. Please use tf.io.parse_single_sequence_example instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 15:41:46.586203: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2022-09-20 15:41:46.661635: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fddccd5bb20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-09-20 15:41:46.661654: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/j7/xx4rywvx1n56yn30273_zs8w0000gn/T/ipykernel_36265/1984207477.py:130: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/envs/py3.7/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "Using 8 threads for parallel map\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Mode train\n",
      "WARNING:tensorflow:From /var/folders/j7/xx4rywvx1n56yn30273_zs8w0000gn/T/ipykernel_36265/3943869059.py:7: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:Enabled internal features: {'job_clicked_embeddings', 'job_content_embeddings'}\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/envs/py3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/junzhu/Dropbox/My Mac (JundeMacBook-Pro.local)/Desktop/Next_application_prediction/4.Train/PAN_model_improved_sampling.py:827: setdiff1d (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "This op will be removed after the deprecation date. Please switch to tf.sets.difference().\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /Users/junzhu/Dropbox/My Mac (JundeMacBook-Pro.local)/Desktop/Next_application_prediction/4.Train/PAN_model_improved_sampling.py:281: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/envs/py3.7/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:271: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /Users/junzhu/Dropbox/My Mac (JundeMacBook-Pro.local)/Desktop/Next_application_prediction/4.Train/PAN_model_improved_sampling.py:589: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "PAN\n",
      "WARNING:tensorflow:From /Users/junzhu/Dropbox/My Mac (JundeMacBook-Pro.local)/Desktop/Next_application_prediction/4.Train/PAN_model_improved_sampling.py:481: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./tmp/30_improved_sampling/PAN_30_256_15_50_0.001_0.0001_1000_100_200/model.ckpt.\n",
      "INFO:tensorflow:loss = 3.0095494, step = 1\n",
      "INFO:tensorflow:global_step/sec: 0.470301\n",
      "INFO:tensorflow:loss = 2.6182816, step = 101 (212.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.361836\n",
      "INFO:tensorflow:loss = 2.1708338, step = 201 (276.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.290771\n",
      "INFO:tensorflow:loss = 2.1499555, step = 301 (343.913 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 391 into ./tmp/30_improved_sampling/PAN_30_256_15_50_0.001_0.0001_1000_100_200/model.ckpt.\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/envs/py3.7/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:global_step/sec: 0.242061\n",
      "INFO:tensorflow:loss = 1.8995731, step = 401 (413.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.203306\n",
      "INFO:tensorflow:loss = 1.8324958, step = 501 (491.872 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 599 into ./tmp/30_improved_sampling/PAN_30_256_15_50_0.001_0.0001_1000_100_200/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.2063112.\n",
      "Using 8 threads for parallel map\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Mode eval\n",
      "INFO:tensorflow:Enabled internal features: {'job_clicked_embeddings', 'job_content_embeddings'}\n",
      "PAN\n",
      "next_job_label_expanded Tensor(\"main/recommendations_ranking/evaluation_metrics/ExpandDims:0\", shape=(?, ?, 1), dtype=int64)\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/envs/py3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/metrics_impl.py:2639: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From /Users/junzhu/Dropbox/My Mac (JundeMacBook-Pro.local)/Desktop/Next_application_prediction/4.Train/PAN_model_improved_sampling.py:877: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /Users/junzhu/Dropbox/My Mac (JundeMacBook-Pro.local)/Desktop/Next_application_prediction/4.Train/utils.py:23: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/junzhu/Dropbox/My Mac (JundeMacBook-Pro.local)/Desktop/Next_application_prediction/4.Train/evaluation.py:44: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
      "\n",
      "{'hitrate_at_n': (<tf.Tensor 'main/recommendations_ranking/evaluation_metrics/hitrate_at_n:0' shape=() dtype=float64>, <tf.Tensor 'main/recommendations_ranking/evaluation_metrics/hitrate_at_n/update:0' shape=() dtype=float64>), 'mrr_at_n': (<tf.Tensor 'main/recommendations_ranking/evaluation_metrics/mrr/mrr_at_n/value:0' shape=() dtype=float32>, <tf.Tensor 'main/recommendations_ranking/evaluation_metrics/mrr/mrr_at_n/update_op:0' shape=() dtype=float32>), 'ndcg_at_n': (<tf.Tensor 'main/recommendations_ranking/evaluation_metrics/ndcg/ndcg_at_n/value:0' shape=() dtype=float32>, <tf.Tensor 'main/recommendations_ranking/evaluation_metrics/ndcg/ndcg_at_n/update_op:0' shape=() dtype=float32>)}\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-09-20T16:20:29Z\n",
      "INFO:tensorflow:Saving jobs state checkpoint from train\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/30_improved_sampling/PAN_30_256_15_50_0.001_0.0001_1000_100_200/model.ckpt-599\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 794, 'batch_unique_jobs_count': 676, 'batch_jobcity_count': 794, 'batch_unique_jobcity_count': 287, 'batch_jobstate_count': 794, 'batch_unique_jobstate_count': 35, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 174, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 31, 'batch_sessions_count': 256, 'batch_same_city_count': 62, 'batch_same_state_count': 30}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 7.867813110351562e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 797, 'batch_unique_jobs_count': 668, 'batch_jobcity_count': 797, 'batch_unique_jobcity_count': 300, 'batch_jobstate_count': 797, 'batch_unique_jobstate_count': 30, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 167, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 30, 'batch_sessions_count': 256, 'batch_same_city_count': 66, 'batch_same_state_count': 29}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 9.775161743164062e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 873, 'batch_unique_jobs_count': 774, 'batch_jobcity_count': 873, 'batch_unique_jobcity_count': 321, 'batch_jobstate_count': 873, 'batch_unique_jobstate_count': 30, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 172, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 30, 'batch_sessions_count': 256, 'batch_same_city_count': 64, 'batch_same_state_count': 28}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 8.106231689453125e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 886, 'batch_unique_jobs_count': 813, 'batch_jobcity_count': 886, 'batch_unique_jobcity_count': 332, 'batch_jobstate_count': 886, 'batch_unique_jobstate_count': 40, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 170, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 37, 'batch_sessions_count': 256, 'batch_same_city_count': 70, 'batch_same_state_count': 37}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 6.198883056640625e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 988, 'batch_unique_jobs_count': 863, 'batch_jobcity_count': 988, 'batch_unique_jobcity_count': 335, 'batch_jobstate_count': 988, 'batch_unique_jobstate_count': 33, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 162, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 30, 'batch_sessions_count': 256, 'batch_same_city_count': 74, 'batch_same_state_count': 29}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 7.152557373046875e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 964, 'batch_unique_jobs_count': 868, 'batch_jobcity_count': 964, 'batch_unique_jobcity_count': 329, 'batch_jobstate_count': 964, 'batch_unique_jobstate_count': 32, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 173, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 34, 'batch_sessions_count': 256, 'batch_same_city_count': 70, 'batch_same_state_count': 32}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 5.9604644775390625e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 960, 'batch_unique_jobs_count': 887, 'batch_jobcity_count': 960, 'batch_unique_jobcity_count': 351, 'batch_jobstate_count': 960, 'batch_unique_jobstate_count': 34, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 172, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 34, 'batch_sessions_count': 256, 'batch_same_city_count': 72, 'batch_same_state_count': 33}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 6.198883056640625e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 1018, 'batch_unique_jobs_count': 898, 'batch_jobcity_count': 1018, 'batch_unique_jobcity_count': 310, 'batch_jobstate_count': 1018, 'batch_unique_jobstate_count': 35, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 159, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 32, 'batch_sessions_count': 256, 'batch_same_city_count': 67, 'batch_same_state_count': 31}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 5.9604644775390625e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 902, 'batch_unique_jobs_count': 827, 'batch_jobcity_count': 902, 'batch_unique_jobcity_count': 347, 'batch_jobstate_count': 902, 'batch_unique_jobstate_count': 34, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 172, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 36, 'batch_sessions_count': 256, 'batch_same_city_count': 80, 'batch_same_state_count': 33}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 7.3909759521484375e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 997, 'batch_unique_jobs_count': 897, 'batch_jobcity_count': 997, 'batch_unique_jobcity_count': 329, 'batch_jobstate_count': 997, 'batch_unique_jobstate_count': 34, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 161, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 30, 'batch_sessions_count': 256, 'batch_same_city_count': 67, 'batch_same_state_count': 29}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 8.106231689453125e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 983, 'batch_unique_jobs_count': 889, 'batch_jobcity_count': 983, 'batch_unique_jobcity_count': 352, 'batch_jobstate_count': 983, 'batch_unique_jobstate_count': 31, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 155, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 30, 'batch_sessions_count': 256, 'batch_same_city_count': 60, 'batch_same_state_count': 28}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 5.9604644775390625e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 959, 'batch_unique_jobs_count': 879, 'batch_jobcity_count': 959, 'batch_unique_jobcity_count': 348, 'batch_jobstate_count': 959, 'batch_unique_jobstate_count': 33, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 179, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 35, 'batch_sessions_count': 256, 'batch_same_city_count': 75, 'batch_same_state_count': 31}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 6.9141387939453125e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 919, 'batch_unique_jobs_count': 825, 'batch_jobcity_count': 919, 'batch_unique_jobcity_count': 317, 'batch_jobstate_count': 919, 'batch_unique_jobstate_count': 33, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 171, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 30, 'batch_sessions_count': 256, 'batch_same_city_count': 79, 'batch_same_state_count': 30}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 8.106231689453125e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 963, 'batch_unique_jobs_count': 894, 'batch_jobcity_count': 963, 'batch_unique_jobcity_count': 340, 'batch_jobstate_count': 963, 'batch_unique_jobstate_count': 34, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 179, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 32, 'batch_sessions_count': 256, 'batch_same_city_count': 79, 'batch_same_state_count': 31}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 8.106231689453125e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 1014, 'batch_unique_jobs_count': 822, 'batch_jobcity_count': 1014, 'batch_unique_jobcity_count': 295, 'batch_jobstate_count': 1014, 'batch_unique_jobstate_count': 26, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 153, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 26, 'batch_sessions_count': 256, 'batch_same_city_count': 55, 'batch_same_state_count': 25}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 7.152557373046875e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 963, 'batch_unique_jobs_count': 807, 'batch_jobcity_count': 963, 'batch_unique_jobcity_count': 300, 'batch_jobstate_count': 963, 'batch_unique_jobstate_count': 31, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 150, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 29, 'batch_sessions_count': 256, 'batch_same_city_count': 73, 'batch_same_state_count': 29}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 7.152557373046875e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 1006, 'batch_unique_jobs_count': 849, 'batch_jobcity_count': 1006, 'batch_unique_jobcity_count': 296, 'batch_jobstate_count': 1006, 'batch_unique_jobstate_count': 30, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 152, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 30, 'batch_sessions_count': 256, 'batch_same_city_count': 65, 'batch_same_state_count': 28}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 6.9141387939453125e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 982, 'batch_unique_jobs_count': 805, 'batch_jobcity_count': 982, 'batch_unique_jobcity_count': 307, 'batch_jobstate_count': 982, 'batch_unique_jobstate_count': 32, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 145, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 26, 'batch_sessions_count': 256, 'batch_same_city_count': 56, 'batch_same_state_count': 24}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 1.0967254638671875e-05\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 1021, 'batch_unique_jobs_count': 820, 'batch_jobcity_count': 1021, 'batch_unique_jobcity_count': 284, 'batch_jobstate_count': 1021, 'batch_unique_jobstate_count': 31, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 151, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 30, 'batch_sessions_count': 256, 'batch_same_city_count': 67, 'batch_same_state_count': 29}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 7.152557373046875e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 1037, 'batch_unique_jobs_count': 850, 'batch_jobcity_count': 1037, 'batch_unique_jobcity_count': 281, 'batch_jobstate_count': 1037, 'batch_unique_jobstate_count': 33, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 162, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 32, 'batch_sessions_count': 256, 'batch_same_city_count': 65, 'batch_same_state_count': 32}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 9.059906005859375e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 988, 'batch_unique_jobs_count': 811, 'batch_jobcity_count': 988, 'batch_unique_jobcity_count': 318, 'batch_jobstate_count': 988, 'batch_unique_jobstate_count': 31, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 161, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 30, 'batch_sessions_count': 256, 'batch_same_city_count': 78, 'batch_same_state_count': 28}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 7.867813110351562e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 1002, 'batch_unique_jobs_count': 801, 'batch_jobcity_count': 1002, 'batch_unique_jobcity_count': 283, 'batch_jobstate_count': 1002, 'batch_unique_jobstate_count': 31, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 161, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 29, 'batch_sessions_count': 256, 'batch_same_city_count': 57, 'batch_same_state_count': 29}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 6.9141387939453125e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 935, 'batch_unique_jobs_count': 812, 'batch_jobcity_count': 935, 'batch_unique_jobcity_count': 308, 'batch_jobstate_count': 935, 'batch_unique_jobstate_count': 32, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 160, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 33, 'batch_sessions_count': 256, 'batch_same_city_count': 69, 'batch_same_state_count': 30}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 6.9141387939453125e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 1077, 'batch_unique_jobs_count': 856, 'batch_jobcity_count': 1077, 'batch_unique_jobcity_count': 291, 'batch_jobstate_count': 1077, 'batch_unique_jobstate_count': 31, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 146, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 31, 'batch_sessions_count': 256, 'batch_same_city_count': 55, 'batch_same_state_count': 28}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 8.106231689453125e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 1003, 'batch_unique_jobs_count': 842, 'batch_jobcity_count': 1003, 'batch_unique_jobcity_count': 319, 'batch_jobstate_count': 1003, 'batch_unique_jobstate_count': 33, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 145, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 32, 'batch_sessions_count': 256, 'batch_same_city_count': 70, 'batch_same_state_count': 32}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 7.152557373046875e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 983, 'batch_unique_jobs_count': 850, 'batch_jobcity_count': 983, 'batch_unique_jobcity_count': 308, 'batch_jobstate_count': 983, 'batch_unique_jobstate_count': 31, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 166, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 30, 'batch_sessions_count': 256, 'batch_same_city_count': 70, 'batch_same_state_count': 28}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 7.152557373046875e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 1089, 'batch_unique_jobs_count': 884, 'batch_jobcity_count': 1089, 'batch_unique_jobcity_count': 345, 'batch_jobstate_count': 1089, 'batch_unique_jobstate_count': 31, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 164, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 30, 'batch_sessions_count': 256, 'batch_same_city_count': 71, 'batch_same_state_count': 28}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 5.9604644775390625e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 1046, 'batch_unique_jobs_count': 870, 'batch_jobcity_count': 1046, 'batch_unique_jobcity_count': 307, 'batch_jobstate_count': 1046, 'batch_unique_jobstate_count': 30, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 166, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 30, 'batch_sessions_count': 256, 'batch_same_city_count': 76, 'batch_same_state_count': 28}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 6.198883056640625e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 1041, 'batch_unique_jobs_count': 832, 'batch_jobcity_count': 1041, 'batch_unique_jobcity_count': 303, 'batch_jobstate_count': 1041, 'batch_unique_jobstate_count': 35, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 161, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 32, 'batch_sessions_count': 256, 'batch_same_city_count': 61, 'batch_same_state_count': 29}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 7.152557373046875e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 1039, 'batch_unique_jobs_count': 871, 'batch_jobcity_count': 1039, 'batch_unique_jobcity_count': 316, 'batch_jobstate_count': 1039, 'batch_unique_jobstate_count': 30, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 160, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 29, 'batch_sessions_count': 256, 'batch_same_city_count': 75, 'batch_same_state_count': 28}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 7.152557373046875e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 982, 'batch_unique_jobs_count': 835, 'batch_jobcity_count': 982, 'batch_unique_jobcity_count': 312, 'batch_jobstate_count': 982, 'batch_unique_jobstate_count': 35, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 173, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 29, 'batch_sessions_count': 256, 'batch_same_city_count': 78, 'batch_same_state_count': 29}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 5.9604644775390625e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 971, 'batch_unique_jobs_count': 793, 'batch_jobcity_count': 971, 'batch_unique_jobcity_count': 305, 'batch_jobstate_count': 971, 'batch_unique_jobstate_count': 32, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 160, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 32, 'batch_sessions_count': 256, 'batch_same_city_count': 61, 'batch_same_state_count': 31}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 5.7220458984375e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 981, 'batch_unique_jobs_count': 814, 'batch_jobcity_count': 981, 'batch_unique_jobcity_count': 304, 'batch_jobstate_count': 981, 'batch_unique_jobstate_count': 32, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 169, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 38, 'batch_sessions_count': 256, 'batch_same_city_count': 66, 'batch_same_state_count': 31}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 5.9604644775390625e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 1031, 'batch_unique_jobs_count': 875, 'batch_jobcity_count': 1031, 'batch_unique_jobcity_count': 333, 'batch_jobstate_count': 1031, 'batch_unique_jobstate_count': 33, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 155, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 32, 'batch_sessions_count': 256, 'batch_same_city_count': 72, 'batch_same_state_count': 31}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 6.198883056640625e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 975, 'batch_unique_jobs_count': 804, 'batch_jobcity_count': 975, 'batch_unique_jobcity_count': 310, 'batch_jobstate_count': 975, 'batch_unique_jobstate_count': 33, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 156, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 35, 'batch_sessions_count': 256, 'batch_same_city_count': 67, 'batch_same_state_count': 32}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 8.106231689453125e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 997, 'batch_unique_jobs_count': 837, 'batch_jobcity_count': 997, 'batch_unique_jobcity_count': 318, 'batch_jobstate_count': 997, 'batch_unique_jobstate_count': 32, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 163, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 35, 'batch_sessions_count': 256, 'batch_same_city_count': 74, 'batch_same_state_count': 32}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 6.9141387939453125e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 959, 'batch_unique_jobs_count': 812, 'batch_jobcity_count': 959, 'batch_unique_jobcity_count': 296, 'batch_jobstate_count': 959, 'batch_unique_jobstate_count': 32, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 154, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 32, 'batch_sessions_count': 256, 'batch_same_city_count': 71, 'batch_same_state_count': 28}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 5.9604644775390625e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 1046, 'batch_unique_jobs_count': 867, 'batch_jobcity_count': 1046, 'batch_unique_jobcity_count': 335, 'batch_jobstate_count': 1046, 'batch_unique_jobstate_count': 31, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 168, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 32, 'batch_sessions_count': 256, 'batch_same_city_count': 71, 'batch_same_state_count': 29}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 6.9141387939453125e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 1012, 'batch_unique_jobs_count': 853, 'batch_jobcity_count': 1012, 'batch_unique_jobcity_count': 326, 'batch_jobstate_count': 1012, 'batch_unique_jobstate_count': 32, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 161, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 34, 'batch_sessions_count': 256, 'batch_same_city_count': 67, 'batch_same_state_count': 30}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 2.09808349609375e-05\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 949, 'batch_unique_jobs_count': 791, 'batch_jobcity_count': 949, 'batch_unique_jobcity_count': 290, 'batch_jobstate_count': 949, 'batch_unique_jobstate_count': 30, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 143, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 30, 'batch_sessions_count': 256, 'batch_same_city_count': 71, 'batch_same_state_count': 29}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 6.9141387939453125e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 1028, 'batch_unique_jobs_count': 824, 'batch_jobcity_count': 1028, 'batch_unique_jobcity_count': 291, 'batch_jobstate_count': 1028, 'batch_unique_jobstate_count': 34, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 160, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 33, 'batch_sessions_count': 256, 'batch_same_city_count': 66, 'batch_same_state_count': 31}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 2.288818359375e-05\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 1012, 'batch_unique_jobs_count': 856, 'batch_jobcity_count': 1012, 'batch_unique_jobcity_count': 315, 'batch_jobstate_count': 1012, 'batch_unique_jobstate_count': 32, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 163, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 32, 'batch_sessions_count': 256, 'batch_same_city_count': 67, 'batch_same_state_count': 31}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 5.9604644775390625e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 988, 'batch_unique_jobs_count': 842, 'batch_jobcity_count': 988, 'batch_unique_jobcity_count': 305, 'batch_jobstate_count': 988, 'batch_unique_jobstate_count': 31, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 179, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 32, 'batch_sessions_count': 256, 'batch_same_city_count': 72, 'batch_same_state_count': 30}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 6.198883056640625e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 988, 'batch_unique_jobs_count': 824, 'batch_jobcity_count': 988, 'batch_unique_jobcity_count': 298, 'batch_jobstate_count': 988, 'batch_unique_jobstate_count': 30, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 174, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 31, 'batch_sessions_count': 256, 'batch_same_city_count': 68, 'batch_same_state_count': 28}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 6.9141387939453125e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 911, 'batch_unique_jobs_count': 759, 'batch_jobcity_count': 911, 'batch_unique_jobcity_count': 301, 'batch_jobstate_count': 911, 'batch_unique_jobstate_count': 31, 'batch_usercity_count': 256, 'batch_unique_usercity_count': 166, 'batch_userstate_count': 256, 'batch_unique_userstate_count': 31, 'batch_sessions_count': 256, 'batch_same_city_count': 57, 'batch_same_state_count': 28}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 5.0067901611328125e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:batch_stats: {'batch_jobs_count': 943, 'batch_unique_jobs_count': 800, 'batch_jobcity_count': 943, 'batch_unique_jobcity_count': 308, 'batch_jobstate_count': 943, 'batch_unique_jobstate_count': 31, 'batch_usercity_count': 239, 'batch_unique_usercity_count': 147, 'batch_userstate_count': 239, 'batch_unique_userstate_count': 28, 'batch_sessions_count': 239, 'batch_same_city_count': 61, 'batch_same_state_count': 27}\n",
      "INFO:tensorflow:Total elapsed time evaluating benchmarks: 6.9141387939453125e-06\n",
      "INFO:tensorflow:Finished benchmarks evaluation\n",
      "INFO:tensorflow:Evaluation metrics: ['clicks_count':\t45002\n",
      "'hitrate_at_n':\t0.6554763408837951\n",
      "'hitrate_at_n_PAN':\t0.6554763408837951\n",
      "'mrr_at_n':\t0.44242700934410095\n",
      "'mrr_at_n_PAN':\t0.4424269771079626\n",
      "'ndcg_at_n':\t0.4953483045101166\n",
      "'ndcg_at_n_PAN':\t0.4953482697133711\n",
      "'sessions_count':\t11759]\n",
      "INFO:tensorflow:Restoring jobs state checkpoint from train\n",
      "INFO:tensorflow:Finished evaluation at 2022-09-20-16:24:18\n",
      "INFO:tensorflow:Saving dict for global step 599: global_step = 599, hitrate_at_n = 0.6554763408837951, loss = 2.7063575, mrr_at_n = 0.442427, ndcg_at_n = 0.4953483\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 599: ./tmp/30_improved_sampling/PAN_30_256_15_50_0.001_0.0001_1000_100_200/model.ckpt-599\n"
     ]
    }
   ],
   "source": [
    "def get_internal_enabled_features_config():\n",
    "    VALID_INTERNAL_FEATURES = ['job_content_embeddings','job_clicked_embeddings']\n",
    "    internal_features_config = {}\n",
    "    enabled_features = set(VALID_INTERNAL_FEATURES)\n",
    "    for feature in VALID_INTERNAL_FEATURES:\n",
    "        internal_features_config[feature] = (feature in enabled_features)\n",
    "    tf.logging.info('Enabled internal features: {}'.format(enabled_features))\n",
    "    return internal_features_config\n",
    "\n",
    "\n",
    "def module_model_fn(features, labels, mode, params):\n",
    "    print('Mode', mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        negative_samples = params['train_total_negative_samples']\n",
    "        negative_sample_from_buffer = params['train_negative_samples_from_buffer']\n",
    "    \n",
    "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "        negative_samples = params['eval_total_negative_samples']\n",
    "        negative_sample_from_buffer = params['eval_negative_samples_from_buffer']\n",
    "    \n",
    "    elif mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        print('###PREDICT###')\n",
    "        negative_samples = params['eval_total_negative_samples']\n",
    "        negative_sample_from_buffer = params['eval_negative_samples_from_buffer']\n",
    "     \n",
    "        \n",
    "    dropout_keep_prob = params['dropout_keep_prob'] if mode == tf.estimator.ModeKeys.TRAIN else 1.0\n",
    "    internal_features_config = get_internal_enabled_features_config()\n",
    "    \n",
    "    eval_metrics_top_n = params['eval_metrics_top_n']\n",
    "    \n",
    "    model = PAN(mode,\n",
    "                features, \n",
    "                labels,\n",
    "                session_features_config=params['session_features_config'],\n",
    "                job_features_config=params['job_features_config'],\n",
    "                user_features_config=params['user_features_config'],\n",
    "                batch_size=params['batch_size'], \n",
    "                lr=params['lr'],\n",
    "                reg_l2_rate=params['reg_l2_rate'], \n",
    "                dropout_keep_prob=dropout_keep_prob,\n",
    "                softmax_temperature=params['softmax_temperature'], \n",
    "                pretrained_job_content_embeddings=params['pretrained_job_content_embeddings'],\n",
    "                pretrained_job_embedding_size=params['pretrained_job_embedding_size'],\n",
    "                job_metadata=params['job_metadata'],\n",
    "                user_metadata =params['user_metadata'],\n",
    "                negative_samples=negative_samples,\n",
    "                negative_sample_from_buffer=negative_sample_from_buffer,\n",
    "                rnn_num_layers=params['rnn_num_layers'],\n",
    "                rnn_units=params['rnn_units'],\n",
    "                recent_clicks_buffer_max_size=params['recent_clicks_buffer_max_size'],\n",
    "                recent_clicks_for_normalization=params['recent_clicks_for_normalization'],\n",
    "                metrics_top_n=eval_metrics_top_n,\n",
    "                max_cardinality_for_ohe=params['max_cardinality_for_ohe'],\n",
    "                internal_features_config=internal_features_config,\n",
    "                plot_histograms=params['save_histograms']\n",
    "               )\n",
    "    \n",
    "    \n",
    "    #Using these variables as global so that they persist across different train and eval\n",
    "    global clicked_jobs_state, eval_sessions_metrics_log, sessions_negative_jobs_log\n",
    "    \n",
    "    eval_baseline_classifiers = []\n",
    "\n",
    "    attention_log = []\n",
    "    trained_session_embeddings = []\n",
    "    \n",
    "    \n",
    "    hooks = [JobsStateUpdaterHook(mode, \n",
    "                                  model, \n",
    "                                  eval_metrics_top_n=eval_metrics_top_n,\n",
    "                                  clicked_jobs_state=clicked_jobs_state, \n",
    "                                  eval_sessions_metrics_log=eval_sessions_metrics_log,\n",
    "                                  sessions_negative_jobs_log=sessions_negative_jobs_log,\n",
    "                                  sessions_model_recommendations_log=sessions_model_recommendations_log,\n",
    "                                  pretrained_job_content_embeddings = params['pretrained_job_content_embeddings'],\n",
    "                                  job_metadata=params['job_metadata'],\n",
    "                                  user_metadata=params['user_metadata'],\n",
    "                                  eval_baseline_classifiers=eval_baseline_classifiers,\n",
    "                                  attention_log = attention_log,\n",
    "                                  trained_session_embeddings = trained_session_embeddings\n",
    "                                 )] \n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:        \n",
    "        return tf.estimator.EstimatorSpec(mode, loss=model.total_loss, train_op=model.train, training_chief_hooks=hooks)\n",
    "    \n",
    "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "        eval_metrics = {\n",
    "            'hitrate_at_n': (model.recall_at_n, model.recall_at_n_update_op),\n",
    "            'mrr_at_n': (model.mrr, model.mrr_update_op),   \n",
    "            'ndcg_at_n': (model.ndcg_at_n_mean, model.ndcg_at_n_mean_update_op),                 \n",
    "        }\n",
    "        print(eval_metrics)\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=model.total_loss, eval_metric_ops=eval_metrics, evaluation_hooks=hooks) \n",
    "\n",
    "    \n",
    "    else:\n",
    "        predictions = {\n",
    "            'predicted_job_ids': model.predicted_job_ids,\n",
    "            'predicted_job_probs': model.predicted_job_probs,\n",
    "            'att': model.attention,\n",
    "            'job_clicked': model.job_clicked\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions = predictions) \n",
    "\n",
    "\n",
    "\n",
    "def build_estimator(model_dir, job_content_embeddings, job_metadata, user_metadata, job_features_config, session_features_config):\n",
    "    #Disabling GPU (memory issues on local machine)\n",
    "    #config_proto = tf.ConfigProto(device_count={'GPU': 0})    \n",
    "    run_config = tf.estimator.RunConfig(tf_random_seed=RANDOM_SEED,\n",
    "                                        keep_checkpoint_max=1, \n",
    "                                        save_checkpoints_secs=1200, \n",
    "                                        save_summary_steps=100,\n",
    "                                        log_step_count_steps=100,\n",
    "                                        #session_config=config_proto\n",
    "                                        )\n",
    "    \n",
    "    estimator = tf.estimator.Estimator(\n",
    "        config=run_config,\n",
    "        model_dir=model_dir,\n",
    "        model_fn=module_model_fn,    \n",
    "        params={\n",
    "            'batch_size': batch_size,\n",
    "            'lr': learning_rate,\n",
    "            'reg_l2_rate': reg_l2,\n",
    "            'dropout_keep_prob': dropout_keep_prob,\n",
    "            'softmax_temperature': softmax_temperature,\n",
    "            'train_total_negative_samples': train_total_negative_samples,\n",
    "            'train_negative_samples_from_buffer': train_negative_samples_from_buffer,\n",
    "            'eval_total_negative_samples': eval_total_negative_samples,\n",
    "            'eval_negative_samples_from_buffer': eval_negative_samples_from_buffer,\n",
    "            'rnn_num_layers': rnn_num_layers,\n",
    "            'rnn_units': rnn_units,\n",
    "            'recent_clicks_buffer_max_size': recent_clicks_buffer_max_size,\n",
    "            'recent_clicks_for_normalization': recent_clicks_for_normalization,\n",
    "            'eval_metrics_top_n': eval_metrics_top_n,\n",
    "            'max_cardinality_for_ohe': max_cardinality_for_ohe,\n",
    "            'save_histograms': save_histograms,\n",
    "             #From pre-processing\n",
    "            'session_features_config': session_features_config,\n",
    "            'job_features_config': job_features_config,\n",
    "            'user_features_config': user_features_config,\n",
    "            'job_metadata': job_metadata, \n",
    "            'user_metadata': user_metadata,\n",
    "            'pretrained_job_content_embeddings': job_content_embeddings,\n",
    "            'pretrained_job_embedding_size': pretrained_job_embedding_size\n",
    "            \n",
    "            })\n",
    "    return estimator\n",
    "   \n",
    "\n",
    "predict_input_fn = lambda: prepare_dataset_iterator('../data/cb12/sessions_tf/test_14d_30_sessions',session_features_config, batch_size=batch_size, truncate_session_length=truncate_session_length)\n",
    "\n",
    "global eval_sessions_metrics_log, clicked_jobs_statejobs_state, sessions_negative_jobs_log, sessions_model_recommendations_log\n",
    "eval_sessions_metrics_log = []\n",
    "\n",
    "import itertools\n",
    "model_output_dir = './tmp/30_improved_sampling/PAN_30' + '_' + str(batch_size) + '_' + str(train_total_negative_samples) + '_' + str(eval_total_negative_samples) + '_' + str(learning_rate) + '_' + str(reg_l2) + '_' + str(recent_clicks_buffer_max_size) + '_' + str(train_negative_samples_from_buffer) + '_' + str(eval_negative_samples_from_buffer) \n",
    "#model_output_dir = './tmp/30/LSTM_30' + '_' + str(batch_size) + '_' + str(train_total_negative_samples) + '_' + str(eval_total_negative_samples) + '_' + str(learning_rate) + '_' + str(reg_l2) + '_' + str(recent_clicks_buffer_max_size) + '_' + str(train_negative_samples_from_buffer) + '_' + str(eval_negative_samples_from_buffer) \n",
    "\n",
    "print(model_output_dir)\n",
    "model = build_estimator(model_output_dir, job_content_embeddings, job_metadata, user_metadata, job_features_config, session_features_config) \n",
    " \n",
    "predict_input_fn = prepare_dataset_iterator('../data/cb12/sessions_tf/test_14d_30_sessions',session_features_config, batch_size=batch_size, truncate_session_length=truncate_session_length)\n",
    "\n",
    "\n",
    "for epoch in range(1):\n",
    "    model.train(input_fn=lambda: prepare_dataset_iterator('../data/cb12/sessions_tf/train_14d_30_sessions', session_features_config, batch_size=batch_size, truncate_session_length=truncate_session_length))\n",
    "    model.evaluate(input_fn=lambda: prepare_dataset_iterator('../data/cb12/sessions_tf/test_14d_30_sessions', session_features_config, batch_size=batch_size, truncate_session_length=truncate_session_length))\n",
    "    #predictions = list(itertools.islice(model.predict(input_fn=predict_input_fn),10))\n",
    "    #predictions = list(itertools.islice(model.predict(input_fn=predict_input_fn), 10))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145c74ab-dace-4277-b979-73fb52a0b217",
   "metadata": {},
   "source": [
    "# Step 6: Save eval metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a715b68f-7d33-4758-ac91-64e5695eab99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving eval metrics\n",
      "INFO:tensorflow:Saved eval metrics\n",
      "Saving eval metrics\n",
      "INFO:tensorflow:Saved eval metrics\n"
     ]
    }
   ],
   "source": [
    "#After each number of train/eval loops\n",
    "from utils import save_eval_baseline_metrics_csv, save_sessions_negative_jobs, save_sessions_model_recommendations_log\n",
    "\n",
    "print('Saving eval metrics')\n",
    "save_eval_baseline_metrics_csv(eval_sessions_metrics_log, model_output_dir)\n",
    "if save_eval_sessions_negative_samples:\n",
    "    #Flushing to disk the negative samples used to evaluate each sessions, so that benchmarks metrics outside the framework (eg. Matrix Factorization) can be comparable\n",
    "    save_sessions_negative_jobs(model_output_dir, sessions_negative_jobs_log)\n",
    "    sessions_negative_jobs_log = []\n",
    "\n",
    "if save_eval_sessions_recommendations:  \n",
    "    #Flushing to disk the recommended items to test re-ranking approaches (e.g. MMR)\n",
    "    save_sessions_model_recommendations_log(model_output_dir, sessions_model_recommendations_log)\n",
    "    sessions_model_recommendations_log = [] \n",
    "\n",
    "tf.logging.info('Saved eval metrics')#After each number of train/eval loops\n",
    "from utils import save_eval_baseline_metrics_csv, save_sessions_negative_jobs, save_sessions_model_recommendations_log\n",
    "\n",
    "print('Saving eval metrics')\n",
    "save_eval_baseline_metrics_csv(eval_sessions_metrics_log, model_output_dir)\n",
    "if save_eval_sessions_negative_samples:\n",
    "    #Flushing to disk the negative samples used to evaluate each sessions, so that benchmarks metrics outside the framework (eg. Matrix Factorization) can be comparable\n",
    "    save_sessions_negative_jobs(model_output_dir, sessions_negative_jobs_log)\n",
    "    sessions_negative_jobs_log = []\n",
    "\n",
    "if save_eval_sessions_recommendations:  \n",
    "    #Flushing to disk the recommended items to test re-ranking approaches (e.g. MMR)\n",
    "    save_sessions_model_recommendations_log(model_output_dir, sessions_model_recommendations_log)\n",
    "    sessions_model_recommendations_log = [] \n",
    "\n",
    "tf.logging.info('Saved eval metrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b826ab96-cba3-427b-95d2-f827a37a6665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.7",
   "language": "python",
   "name": "py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
