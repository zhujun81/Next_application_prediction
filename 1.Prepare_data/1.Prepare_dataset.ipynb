{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65368c18-5cf5-470b-add3-37e5b6be198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "981fe7aa-f665-450e-9682-788c58a9d227",
   "metadata": {},
   "outputs": [],
   "source": [
    "path =  \"../data/\"\n",
    "dataset = \"cb12/\"\n",
    "\n",
    "raw_path = path + dataset + \"raw/\" \n",
    "interim_path = path + dataset + \"interim/\"\n",
    "processed_path = path + dataset + \"processed/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22af961-47f3-4793-a03a-b8dc9f239aac",
   "metadata": {},
   "source": [
    "# Step 1: Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ab1923-a5b6-425c-955b-ba601897ecc7",
   "metadata": {},
   "source": [
    "### User data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf13eb0e-38df-4394-a1ca-97983d5e618c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(389708, 15)\n",
      "(286569, 15)\n"
     ]
    }
   ],
   "source": [
    "df_user = pd.read_csv(raw_path + 'users.tsv', header=0, sep='\\t')\n",
    "print(df_user.shape)\n",
    "df_user.dropna(axis=0, how='any', thresh=None, subset=['UserID', 'City', 'State', 'Country', 'DegreeType', 'Major', 'WorkHistoryCount', 'TotalYearsExperience'], inplace=True)\n",
    "print(df_user.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dae9599-4023-4d90-a7ed-2f54a140bcc2",
   "metadata": {},
   "source": [
    "### Application records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "462d6bd2-8d14-4504-8db6-7f29ecb448ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1603111, 6)\n"
     ]
    }
   ],
   "source": [
    "df_app = pd.read_csv(raw_path + 'applications.csv', header=0, sep='\\t')\n",
    "print(df_app.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "058d431f-5a7c-4ec9-a355-51c0eaf23dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique Jobs:  365668\n",
      "Number of unique Users:  321235\n",
      "count    321235.000000\n",
      "mean          4.990462\n",
      "std          11.418487\n",
      "min           1.000000\n",
      "25%           1.000000\n",
      "50%           2.000000\n",
      "75%           5.000000\n",
      "max        2473.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unique Jobs: \", len(df_app.JobID.unique()))\n",
    "print(\"Number of unique Users: \", len(df_app.UserID.unique()))\n",
    "print(df_app.groupby('UserID').size().describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859c8bb3-91aa-4a7d-a7dc-a10b301ab71f",
   "metadata": {},
   "source": [
    "### Keep applications only for valid users\n",
    "Valid user: have all infor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0a3a79f-1eb8-4b3c-a5c4-4bcbcd0e6aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1187652, 6)\n",
      "Number of unique Jobs:  321417\n",
      "Number of unique Users:  236343\n"
     ]
    }
   ],
   "source": [
    "df_app_valid = df_app[df_app.UserID.isin(df_user.UserID)]\n",
    "print(df_app_valid.shape)\n",
    "print(\"Number of unique Jobs: \", len(df_app_valid.JobID.unique()))\n",
    "print(\"Number of unique Users: \", len(df_app_valid.UserID.unique()))\n",
    "# print(df_app_valid.groupby('UserID').size().describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38f41657-20ba-4b15-8e59-d57129ea6c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time: 2012-04-01 00:00:21\n",
      "Start Time: 2012-06-26 23:59:50\n"
     ]
    }
   ],
   "source": [
    "print(\"Start Time: {}\".format(pd.to_datetime(df_app_valid[\"ApplicationDate\"].min(), unit=\"s\")))\n",
    "print(\"Start Time: {}\".format(pd.to_datetime(df_app_valid[\"ApplicationDate\"].max(), unit=\"s\")))\n",
    "\n",
    "# remove NaN values\n",
    "df_app_valid = df_app_valid[np.isfinite(df_app_valid['ApplicationDate'])]\n",
    "# convert back to long from float\n",
    "df_app_valid['ApplicationDate'] = df_app_valid['ApplicationDate'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3111d75-377b-43fa-a61a-44b2a5b33225",
   "metadata": {},
   "source": [
    "### Job records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e4f002-178d-487c-8caa-7b66affe9dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job = pd.read_csv(raw_path + \"jobs.tsv\", header=0, sep='\\t', on_bad_lines='skip')\n",
    "print(df_job.shape)\n",
    "df_job['StartDate'] = df_job['StartDate'].astype(\"datetime64[ms]\").astype(np.int64) // 10**9\n",
    "df_job['EndDate'] = df_job['EndDate'].astype(\"datetime64[ms]\").astype(np.int64) // 10**9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b918558a-45f8-4199-987a-01181f34845a",
   "metadata": {},
   "source": [
    "### Drop incomplete rows for comparison purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8664b333-a943-46cc-8116-1d4b26dd235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_job.dropna(axis=0, how='any', thresh=None, subset=['JobID', 'Title', 'Description', 'Requirements', 'City', 'State', 'Country'], inplace=True)\n",
    "# print(df_job.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6fa8ed-149e-4a41-afe8-dc2c01f97819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_job['Requirements'] = df_job['Requirements'].map(lambda x:re.sub('<[^<]+?>', '', x)).map(lambda x:re.sub('\\\\\\\\r', '', x)).map(lambda x:re.sub('\\\\\\\\n', '', x)).map(lambda x:re.sub('&nbsp;', ' ', x)).map(lambda x:re.sub('[—]+', ' ', x)).map(lambda x:re.sub('/', ' ', x))\n",
    "# df_job['Description'] = df_job['Description'].map(lambda x:re.sub('<[^<]+?>', '', x)).map(lambda x:re.sub('\\\\\\\\r', '', x)).map(lambda x:re.sub('\\\\\\\\n', '', x)).map(lambda x:re.sub('&nbsp;', ' ', x)).map(lambda x:re.sub('[—]+', ' ', x)).map(lambda x:re.sub('/', ' ', x))\n",
    "# df_job['Title'] = df_job['Title'].map(lambda x:re.sub('/', ' ', x))\n",
    "\n",
    "# df_job['Requirements'] = df_job['Requirements'].str.lower()\n",
    "# df_job['Description'] = df_job['Description'].str.lower()\n",
    "# df_job['Title'] = df_job['Title'].str.lower()\n",
    "# df_job.to_csv(interim_path + \"jobs_cleaned.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdff3d87-03f9-4594-b216-06249ebe8a2a",
   "metadata": {},
   "source": [
    "### Or load directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7206c070-6625-4380-9f6b-b5a1180fde66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/py3.7/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (9) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique Jobs: 1050503\n",
      "Number of unique Title 413201\n",
      "Number of unique Description: 718456\n",
      "Number of unique Requirements 513490\n",
      "Number of unique Cities: 10995\n",
      "Number of unique States: 60\n",
      "Number of unique countries: 65\n",
      "Number of unique zip codes: 42681\n"
     ]
    }
   ],
   "source": [
    "df_job = pd.read_csv(interim_path + \"jobs_cleaned.tsv\", sep='\\t')\n",
    "print(\"Number of unique Jobs:\", len(df_job.JobID.unique()))\n",
    "print(\"Number of unique Title\", len(df_job.Title.unique()))\n",
    "print(\"Number of unique Description:\", len(df_job.Description.unique()))\n",
    "print(\"Number of unique Requirements\", len(df_job.Requirements.unique()))\n",
    "print(\"Number of unique Cities: \" + str(len(df_job.City.unique())))\n",
    "#print(jobs['city'].value_counts(normalize=True) * 100)\n",
    "print(\"Number of unique States: \" + str(len(df_job.State.unique())))\n",
    "#print(jobs['state'].value_counts(normalize=True) * 100)\n",
    "print(\"Number of unique countries: \" + str(len(df_job.Country.unique())))\n",
    "#print(jobs['country'].value_counts(normalize=True) * 100)\n",
    "print(\"Number of unique zip codes: \" + str(len(df_job.Zip5.unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df07f74-6b6e-4cc6-8e37-8f7f7175f5f6",
   "metadata": {},
   "source": [
    "### Add job information to df_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ec84e3a-f501-46eb-a0e9-d4a9a02706ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1171649, 16)\n"
     ]
    }
   ],
   "source": [
    "df_app_new = pd.merge(df_app_valid, df_job, on='JobID', how='inner')\n",
    "df_app_new.sort_values(by=['UserID'], inplace=True)\n",
    "df_app_new.drop(columns='WindowID_y',inplace=True)\n",
    "df_app_new.rename(columns = {'WindowID_x': 'WindowID'}, inplace = True)\n",
    "print(df_app_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e52b583-15bd-4bea-b1e8-6e2a56e746c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique Jobs:  313457\n",
      "Number of unique Users:  234818\n",
      "count    234818.000000\n",
      "mean          4.989605\n",
      "std          11.911864\n",
      "min           1.000000\n",
      "25%           1.000000\n",
      "50%           2.000000\n",
      "75%           5.000000\n",
      "max        2445.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unique Jobs: \", len(df_app_new.JobID.unique()))\n",
    "print(\"Number of unique Users: \", len(df_app_new.UserID.unique()))\n",
    "print(df_app_new.groupby('UserID').size().describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dad35bc-a0f5-487d-bbc1-b0d85f9765eb",
   "metadata": {},
   "source": [
    "# Step 2: Make sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2048a8e-f5da-4a6d-a08a-df31713e41a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sessions(data, session_threshold = 30*60, is_ordered = False, user_key = 'UserID', job_key = 'JobID', time_key = 'ApplicationDate'):\n",
    "    # Assigns sessionn ids to the events in data without grouping keys\n",
    "    if not is_ordered:\n",
    "        # Sort data by user and time\n",
    "        data.sort_values(by=[user_key, time_key], ascending=True, inplace=True)\n",
    "        \n",
    "        # Compute the time difference between queriest\n",
    "        time_diff = np.diff(data[time_key].values)\n",
    "        \n",
    "        # Check which of them are bigger than session_threshold\n",
    "        split_session = time_diff > session_threshold\n",
    "        split_session = np.r_[True, split_session]\n",
    "        \n",
    "        # Check when the user changes is data\n",
    "        new_user = data['UserID'].values[1:] != data['UserID'].values[:-1]\n",
    "        new_user = np.r_[True, new_user]\n",
    "        \n",
    "        # A new sessions stars when at least one of the two conditions is verified\n",
    "        new_session = np.logical_or(new_user, split_session)\n",
    "        \n",
    "        # Compute the session ids\n",
    "        session_ids = np.cumsum(new_session)\n",
    "        data['SessionID'] = session_ids\n",
    "        return data  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52697181-7f3c-4860-8db9-810cb25e0c0e",
   "metadata": {},
   "source": [
    "### 30mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecee05b-97d2-4b67-95eb-6f2ac84ba9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sessions_30 = make_sessions(df_app_new, session_threshold=30 * 60, time_key='ApplicationDate', is_ordered=False)\n",
    "print(df_sessions_30.shape)\n",
    "print(df_sessions_30.head(10))\n",
    "\n",
    "# Drop duplicate interactions\n",
    "df_sessions_30 = df_sessions_30.drop_duplicates(['SessionID','ApplicationDate'])\n",
    "print(df_sessions_30.shape)\n",
    "\n",
    "print('Original data:')\n",
    "print('Num jobs: {}'.format(df_sessions_30.JobID.nunique()))\n",
    "print('Num users: {}'.format(df_sessions_30.UserID.nunique()))\n",
    "print('Num sessions: {}'.format(df_sessions_30.SessionID.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f19b22c-0dee-4ac0-81a5-c19544b6985f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/py3.7/lib/python3.7/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(968885, 17)\n",
      "Number of jobs with >= 1 applications:  301901\n",
      "(968885, 17)\n",
      "Number of sessions with >= 2 applications:  173627\n",
      "(676814, 17)\n",
      "Filtered data:\n",
      "Num jobs: 225268\n",
      "Num users: 117301\n",
      "Num sessions: 173627\n",
      "(676814, 17)\n"
     ]
    }
   ],
   "source": [
    "print('Filtering data')\n",
    "# Drop duplicate applications within the same session\n",
    "df_sessions_30.drop_duplicates(subset=['JobID', 'UserID'], keep='first', inplace=True)\n",
    "print(df_sessions_30.shape)\n",
    "\n",
    "# Keep jobs with >=1 applications\n",
    "job_pop = df_sessions_30.JobID.value_counts()\n",
    "#good_items = item_pop[item_pop >= 5].index\n",
    "good_jobs = job_pop[job_pop >= 1].index\n",
    "print('Number of jobs with >= 1 applications: ', len(good_jobs))\n",
    "df_session_dense_30 = df_sessions_30[df_sessions_30.JobID.isin(good_jobs)]\n",
    "print(df_session_dense_30.shape)\n",
    "\n",
    "\n",
    "# Remove sessions with length < 2\n",
    "session_length = df_session_dense_30.SessionID.value_counts()\n",
    "good_sessions = session_length[session_length >= 2].index\n",
    "print('Number of sessions with >= 2 applications: ', len(good_sessions))\n",
    "df_session_dense_30 = df_session_dense_30[df_session_dense_30.SessionID.isin(good_sessions)]\n",
    "print(df_session_dense_30.shape)\n",
    "\n",
    "# Keep only returning users (with >= 1 sessions) and remove overly active ones (>=200 sessions)\n",
    "sess_per_user = df_session_dense_30.groupby('UserID')['SessionID'].nunique()\n",
    "good_users = sess_per_user[(sess_per_user >= 1) & (sess_per_user < 200000)].index\n",
    "df_session_dense_30 = df_session_dense_30[df_session_dense_30.UserID.isin(good_users)]\n",
    "print('Filtered data:')\n",
    "print('Num jobs: {}'.format(df_session_dense_30.JobID.nunique()))\n",
    "print('Num users: {}'.format(df_session_dense_30.UserID.nunique()))\n",
    "print('Num sessions: {}'.format(df_session_dense_30.SessionID.nunique()))\n",
    "print(df_session_dense_30.shape)\n",
    "\n",
    "# store_path = \"../data/cb12/\"\n",
    "# df_session_dense_30.to_csv(store_path + \"session_filtered_30_consider_user.csv\", sep='\\t')\n",
    "df_session_dense_30.to_csv(interim_path + \"session_filtered_30_consider_user.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c5941a-9cff-451a-9b96-5adc3b3dca18",
   "metadata": {},
   "source": [
    "# Step 3. Create train and test set \n",
    "a time-based (14 days) split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be410ba6-ef62-4e2f-92dd-e3de15c97cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_n_days_out_split(data, n=1, user_key = 'UserID', job_key = 'JobID', session_key = 'SessionID', time_key = 'ApplicationDate', clean_test=True, min_session_length=2):\n",
    "    \"\"\"\n",
    "    Assign the sessions in the last n days to the test set and remaining to the training one\n",
    "    \"\"\"\n",
    "    DAY = 24 * 60 * 60\n",
    "    data.sort_values(by=[user_key, time_key], inplace=True)\n",
    "    end_time = data[time_key].max()\n",
    "    print('end_time', end_time)\n",
    "    test_start = end_time - n * DAY\n",
    "    print('test_start', test_start)\n",
    "    \n",
    "    # get train and test indicies\n",
    "    session_max_times = data.groupby(session_key)[time_key].max()\n",
    "    session_train = session_max_times[session_max_times < test_start].index\n",
    "    session_test = session_max_times[session_max_times >= test_start].index\n",
    "    \n",
    "    \n",
    "    # in1d: Returns a boolean array the same length as ar1 that is True where an element of ar1 is in ar2 and False otherwise.\n",
    "    train = data[np.in1d(data[session_key], session_train)].copy()\n",
    "    test = data[np.in1d(data[session_key], session_test)].copy()\n",
    "    \n",
    "    if clean_test:\n",
    "        before_jobs = len(test[job_key].unique())\n",
    "        # Remove jobs which do not occur in the train set\n",
    "        test = test[np.in1d(test[job_key],train[job_key])]\n",
    "        after_jobs = len(test[job_key].unique())\n",
    "        print(\"Before job count: \" + str(before_jobs))\n",
    "        print(\"After job count: \" + str(after_jobs))\n",
    "        \n",
    "        \n",
    "        # Remove sessions in test shorter than min_session_length\n",
    "        tslength = test.groupby(session_key).size()\n",
    "        test = test[np.in1d(test[session_key],tslength[tslength >= min_session_length].index)].copy()\n",
    "    \n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1646d44-dca1-40d9-ab25-1cf2dc3b3c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end_time 1340755190\n",
      "test_start 1339545590\n",
      "Before job count: 31355\n",
      "After job count: 14059\n",
      "end_time 1339545569\n",
      "test_start 1338335969\n",
      "Before job count: 45802\n",
      "After job count: 17298\n"
     ]
    }
   ],
   "source": [
    "train_full_sessions_30, test_sessions_30 = last_n_days_out_split(df_session_dense_30, n=14, user_key = 'UserID', job_key = 'JobID', session_key = 'SessionID', time_key = 'ApplicationDate', clean_test=True)\n",
    "train_valid_sessions_30, valid_sessions_30 = last_n_days_out_split(train_full_sessions_30, n=14, user_key = 'UserID', job_key = 'JobID', session_key = 'SessionID', time_key = 'ApplicationDate', clean_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8f05856-bbce-4df8-af0d-517a9dff4e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(586434, 17)\n",
      "(52035, 17)\n",
      "(465084, 17)\n",
      "(54676, 17)\n"
     ]
    }
   ],
   "source": [
    "print(train_full_sessions_30.shape)\n",
    "print(test_sessions_30.shape)\n",
    "print(train_valid_sessions_30.shape)\n",
    "print(valid_sessions_30.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71b918de-2c80-4f6b-9fe9-6fdd8c9848fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Jobs: 207972\n",
      "Number of Training Users: 104583\n",
      "Number of Training Sessions: 153268\n",
      "\n",
      "Number of Testing Jobs: 13166\n",
      "Number of Testing Users: 10031\n",
      "Number of Testing Sessions: 11759\n"
     ]
    }
   ],
   "source": [
    "# print statistics\n",
    "train_job_len = len(train_full_sessions_30.JobID.unique())\n",
    "print(\"Number of Training Jobs: \" + str(train_job_len))\n",
    "train_user_len = len(train_full_sessions_30.UserID.unique())\n",
    "print(\"Number of Training Users: \" + str(train_user_len))\n",
    "train_len = len(train_full_sessions_30.SessionID.unique())\n",
    "print(\"Number of Training Sessions: \" + str(train_len))\n",
    "print()\n",
    "\n",
    "test_job_len = len(test_sessions_30.JobID.unique())\n",
    "print(\"Number of Testing Jobs: \" + str(test_job_len))\n",
    "test_user_len = len(test_sessions_30.UserID.unique())\n",
    "print(\"Number of Testing Users: \" + str(test_user_len))\n",
    "test_len = len(test_sessions_30.SessionID.unique())\n",
    "print(\"Number of Testing Sessions: \" + str(test_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22850d4f-2615-4edf-be4b-d39716d42360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(638469, 17)\n",
      "Number of Train + Test Jobs: 207972\n",
      "\n",
      "\n",
      "Number of Train + Test Users: 111785\n",
      "\n",
      "\n",
      "Number of Train + Test Sessions: 165027\n",
      "\n",
      "\n",
      "Number of Train Validating Sessions: 127412\n",
      "Number of Test Validating Sessions: 12343\n"
     ]
    }
   ],
   "source": [
    "merged_jobs_30 = train_full_sessions_30.append(test_sessions_30, ignore_index=True)\n",
    "print(merged_jobs_30.shape)\n",
    "merged_job_len = len(merged_jobs_30.JobID.unique())\n",
    "print(\"Number of Train + Test Jobs: \" + str(merged_job_len))\n",
    "print('\\n')\n",
    "merged_user_len = len(merged_jobs_30.UserID.unique())\n",
    "print(\"Number of Train + Test Users: \" + str(merged_user_len))\n",
    "print('\\n')\n",
    "\n",
    "print(\"Number of Train + Test Sessions: \" + str(train_len + test_len))\n",
    "print('\\n')\n",
    "\n",
    "print(\"Number of Train Validating Sessions: \" + str(len(train_valid_sessions_30.SessionID.unique())))\n",
    "print(\"Number of Test Validating Sessions: \" + str(len(valid_sessions_30.SessionID.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb58566e-617a-493b-8c00-0233ab889e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full_sessions_30.to_csv(processed_path + \"train_14d_30_consider_user.csv\", sep='\\t')\n",
    "test_sessions_30.to_csv(processed_path + \"test_14d_30_consider_user.csv\", sep='\\t')\n",
    "train_valid_sessions_30.to_csv(processed_path + \"valid_train_14d_30_consider_user.csv\", sep='\\t')\n",
    "valid_sessions_30.to_csv(processed_path + \"valid_test_14d_30_consider_user.csv\", sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.7",
   "language": "python",
   "name": "py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
