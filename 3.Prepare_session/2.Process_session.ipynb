{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d27ba2a1-75e5-4fa6-b672-d96c3776079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "import argparse\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c52bf6d-1a45-4371-af3a-441fb8d4935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path =  \"../data/\"\n",
    "dataset = \"cb12/\"\n",
    "\n",
    "raw_path = path + dataset + \"raw/\" \n",
    "interim_path = path + dataset + \"interim/\"\n",
    "processed_path = path + dataset + \"processed/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4045e764-36ad-47fd-9c9e-af532dd0a48d",
   "metadata": {},
   "source": [
    "# Step 1: Load sessions from JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76331ad9-2969-4841-b7f9-759ee48badbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sessions_from_json(json_path):\n",
    "    with open(json_path, 'r') as  f:\n",
    "        sessions = json.load(f)\n",
    "    return sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3df6f542-2ac5-4097-9700-dfd48b366622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153268\n",
      "11759\n"
     ]
    }
   ],
   "source": [
    "sessions_train_30 = load_sessions_from_json(\"../data/cb12/sessions_json/train_14d_30_sessions\")\n",
    "sessions_test_30 = load_sessions_from_json( \"../data/cb12/sessions_json/test_14d_30_sessions\")\n",
    "print(len(sessions_train_30))\n",
    "print(len(sessions_test_30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabe2b26-9dc3-4a3e-bcc2-a0d04ea4ea02",
   "metadata": {},
   "source": [
    "# Step 2: Process session features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdbadadf-ff74-48f7-a64f-a3cfc7485b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_session_clicks_features(list_sessions):\n",
    "    sessions = []\n",
    "    session_count = 0\n",
    "    clicked_jobs_ids = []\n",
    "    unique_clicked_jobs = set()\n",
    "    \n",
    "    for session in list_sessions:\n",
    "        session_count += 1\n",
    "        for click in session['Clicks']:\n",
    "            #Copying click attributes as lists in the session\n",
    "            for key in click:\n",
    "                if key != \"UserID_encoded\" and key != \"WindowID\":\n",
    "                    if key not in session:\n",
    "                        session[key] = [click[key]]\n",
    "                        \n",
    "                    else:\n",
    "                        session[key].append(click[key])\n",
    "            \n",
    "            clicked_jobs_ids.append(click['JobID_encoded'])\n",
    "            unique_clicked_jobs.add(click['JobID_encoded'])\n",
    "        \n",
    "        #Removing clicks property, as its values were copied to individual list columns\n",
    "        del session['Clicks']\n",
    "        sessions.append(session)\n",
    "    \n",
    "    #Ensuring sessions are sorted by WindowID (time)\n",
    "    sessions_df = pd.DataFrame(sessions).sort_values('WindowID')\n",
    "    \n",
    "    #Printing stats\n",
    "    clicks_by_jobs_counter = dict(Counter(clicked_jobs_ids))\n",
    "    clicks_by_jobs = np.array(list(clicks_by_jobs_counter.values()))\n",
    "    total_clicks = np.sum(clicks_by_jobs)\n",
    "    clicks_by_jobs_norm = clicks_by_jobs / total_clicks\n",
    "    clicks_by_jobs_norm_mean = np.mean(clicks_by_jobs_norm)\n",
    "    clicks_by_jobs_norm_median = np.median(clicks_by_jobs_norm)\n",
    "    \n",
    "    stats = {'session_count': session_count,\n",
    "             'clicks': total_clicks,\n",
    "             'clicks_by_session': total_clicks / session_count,\n",
    "             'unique_jobs': len(unique_clicked_jobs),\n",
    "             'clicks_by_job':float(total_clicks)/len(unique_clicked_jobs),\n",
    "             'norm_pop_mean': clicks_by_jobs_norm_mean,\n",
    "             'norm_pop_median': clicks_by_jobs_norm_median,\n",
    "             #'gini_index': gini_index(clicks_by_jobs.astype(np.float32))\n",
    "    }\n",
    "    \n",
    "    print(\"Stats :{}\".format(stats))\n",
    "    return sessions_df, stats, clicks_by_jobs_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3c459ef-b62f-4753-8b2a-95ccb12ecfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats :{'session_count': 153268, 'clicks': 586434, 'clicks_by_session': 3.8261998590703867, 'unique_jobs': 207972, 'clicks_by_job': 2.81977381570596, 'norm_pop_mean': 4.808339584174792e-06, 'norm_pop_median': 1.7052217299815496e-06}\n",
      "Stats :{'session_count': 11759, 'clicks': 52035, 'clicks_by_session': 4.425121183774131, 'unique_jobs': 13166, 'clicks_by_job': 3.9522254291356522, 'norm_pop_mean': 7.595321282090232e-05, 'norm_pop_median': 3.843566830018257e-05}\n"
     ]
    }
   ],
   "source": [
    "sessions_train_df_30, train_stats_30, train_clicks_by_jobs_counter_30 = process_session_clicks_features(sessions_train_30)\n",
    "sessions_test_df_30, test_stats_30, test_clicks_by_jobs_counter_30 = process_session_clicks_features(sessions_test_30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd7c98a-bca8-4d1f-a34c-25d4b281213f",
   "metadata": {},
   "source": [
    "# Step 3: Export sessions to tf records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "740e7d86-972e-4d03-b476-05acf3439ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from tensorflow.python.lib.io import tf_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beb5edca-a9fd-4853-9a88-dc5c21b2beda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sequential_feature(values, vtype=int):\n",
    "    if vtype == int:\n",
    "        features = [tf.train.Feature(int64_list=tf.train.Int64List(value=[value])) for value in values]\n",
    "    elif vtype == float:\n",
    "        features = [tf.train.Feature(float_list=tf.train.FloatList(value=[value])) for value in values]\n",
    "    elif vtype == str:\n",
    "        features = [tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.encode()])) for value in values]\n",
    "    return tf.train.FeatureList(feature=features)\n",
    "\n",
    "\n",
    "\n",
    "def make_sequence_example(row):\n",
    "    context_features = {        \n",
    "        'SessionID': tf.train.Feature(int64_list=tf.train.Int64List(value=[row['SessionID']])),                \n",
    "        'SessionSize': tf.train.Feature(int64_list=tf.train.Int64List(value=[row['SessionSize']])),\n",
    "        'SessionStart': tf.train.Feature(int64_list=tf.train.Int64List(value=[row['SessionStart']])),\n",
    "        'UserID': tf.train.Feature(int64_list=tf.train.Int64List(value=[row['UserID_encoded']])),        \n",
    "    }\n",
    "    \n",
    "    context = tf.train.Features(feature=context_features)\n",
    "    \n",
    "    sequence_features = {\n",
    "        'ApplicationDate': make_sequential_feature(row['ApplicationDate']),\n",
    "        #Categorical features\n",
    "        'Job_clicked': make_sequential_feature(row[\"JobID_encoded\"]),\n",
    "        'JobCity': make_sequential_feature(row[\"JobCity_encoded\"]),\n",
    "        'JobState': make_sequential_feature(row[\"JobState_encoded\"]),\n",
    "        'JobCountry': make_sequential_feature(row[\"JobCountry_encoded\"]),\n",
    "        'UserCity': make_sequential_feature(row[\"UserCity_encoded\"]),\n",
    "        'UserState': make_sequential_feature(row[\"UserState_encoded\"]),\n",
    "        'UserCountry': make_sequential_feature(row[\"UserCountry_encoded\"]),\n",
    "        'UserDegree': make_sequential_feature(row[\"UserDegree_encoded\"]),\n",
    "        'UserMajor': make_sequential_feature(row[\"UserMajor_encoded\"]),\n",
    "    }    \n",
    "\n",
    "    sequence_feature_lists = tf.train.FeatureLists(feature_list=sequence_features)\n",
    "    \n",
    "    return tf.train.SequenceExample(feature_lists=sequence_feature_lists, context=context)    \n",
    "\n",
    "\n",
    "def save_rows_to_tf_record_file(rows, make_sequence_example_fn, export_filename):\n",
    "    tf_record_options = tf_record.TFRecordOptions(tf_record.TFRecordCompressionType.GZIP)\n",
    "\n",
    "    tf_writer = tf_record.TFRecordWriter(export_filename, options=tf_record_options)\n",
    "    try:\n",
    "        for row in rows:\n",
    "            seq_example = make_sequence_example_fn(row)\n",
    "            tf_writer.write(seq_example.SerializeToString())\n",
    "    finally:\n",
    "        tf_writer.close()\n",
    "        sys.stdout.flush()    \n",
    "\n",
    "        \n",
    "def export_sessions_to_tf_records(sessions_df, output_path):        \n",
    "    save_rows_to_tf_record_file(map(lambda x: x[1], sessions_df.iterrows()), make_sequence_example, export_filename=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db6287a6-7033-4291-91a9-342408b46c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11759, 15)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_sessions_to_tf_records(sessions_train_df_30, output_path=\"../data/cb12/sessions_tf/train_14d_30_sessions\")\n",
    "export_sessions_to_tf_records(sessions_test_df_30, output_path=\"../data/cb12/sessions_tf/test_14d_30_sessions\")\n",
    "sessions_test_df_30.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9bb070-95c5-49ae-8dd5-051e59e10c63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.7",
   "language": "python",
   "name": "py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
