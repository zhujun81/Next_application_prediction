{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25e2c1f8-df45-44c6-8166-e24b2083d2f3",
   "metadata": {},
   "source": [
    "Transform applications into sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1dd60ad-0fd8-467a-878e-2e19149d1c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "import argparse\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0b94dae-4529-4d44-b14c-eec40397aff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path =  \"../data/\"\n",
    "dataset = \"cb12/\"\n",
    "\n",
    "raw_path = path + dataset + \"raw/\" \n",
    "interim_path = path + dataset + \"interim/\"\n",
    "processed_path = path + dataset + \"processed/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd47f95-539f-435a-8f43-a6ce438fc34d",
   "metadata": {},
   "source": [
    "# Step 1: Load feature encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77e2e997-c628-423c-ad6e-91213eddb792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize(filename, obj):\n",
    "    with tf.io.gfile.GFile(filename, 'wb') as handle:\n",
    "        pickle.dump(obj, handle)\n",
    "\n",
    "def deserialize(filename):\n",
    "    with tf.io.gfile.GFile(filename, 'rb') as handle:\n",
    "        return pickle.load(handle)\n",
    "    \n",
    "def load_feature_encoders(path):\n",
    "    features_encoders = deserialize(path)\n",
    "    return features_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "137e979b-fcd4-4ffc-80dd-3546d9982f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_features_encoders_30 = load_feature_encoders(processed_path + 'job_feature_encoders_14d_30_consider_user.pickle')\n",
    "user_features_encoders_30 = load_feature_encoders(processed_path + 'user_feature_encoders_14d_30_consider_user.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd631df-d873-4b3c-86a8-ca3625289cf3",
   "metadata": {},
   "source": [
    "# Step 2: Load user meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "676aa69c-3da6-412e-b22e-8074cd334c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading user from file: ../data/cb12/processed/users_14d_30_consider_user_encoded.csv\n",
      "(111785, 21)\n"
     ]
    }
   ],
   "source": [
    "print('Loading user from file: {}'.format(processed_path + 'users_14d_30_consider_user_encoded.csv'))\n",
    "user_df_30 = pd.read_csv(processed_path + 'users_14d_30_consider_user_encoded.csv', header=0, sep='\\t')\n",
    "print(user_df_30.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5097302a-0bb8-44cf-baeb-668eb61603c1",
   "metadata": {},
   "source": [
    "# Step 3: Load application data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfc52905-91b5-491b-b520-f7512eba8b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categ_feature(value, encoder_dict):\n",
    "    if value in encoder_dict:\n",
    "        return encoder_dict[value]\n",
    "    else:\n",
    "        return encoder_dict[get_unfrequent_token()]\n",
    "\n",
    "def transform_categorical_column(series, encoder):\n",
    "    return series.apply(lambda x: encode_categ_feature(x, encoder)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "768bec42-2310-4c03-ac03-853b5202a59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(586434, 18)\n",
      "(586434, 22)\n",
      "(52035, 18)\n",
      "(52035, 22)\n"
     ]
    }
   ],
   "source": [
    "train_df_30 = pd.read_csv(processed_path + 'train_14d_30_consider_user.csv', sep='\\t')\n",
    "print(train_df_30.shape)\n",
    "train_df_30.rename(columns={\"City\": \"JobCity\", \"State\": \"JobState\", \"Country\": \"JobCountry\"}, inplace = True)\n",
    "train_df_30['JobID_encoded'] = transform_categorical_column(train_df_30['JobID'], job_features_encoders_30['JobID'])\n",
    "train_df_30['JobCity_encoded'] = transform_categorical_column(train_df_30['JobCity'], job_features_encoders_30['JobCity'])\n",
    "train_df_30['JobState_encoded'] = transform_categorical_column(train_df_30['JobState'], job_features_encoders_30['JobState'])\n",
    "train_df_30['JobCountry_encoded'] = transform_categorical_column(train_df_30['JobCountry'], job_features_encoders_30['JobCountry'])\n",
    "print(train_df_30.shape)\n",
    "\n",
    "test_df_30 = pd.read_csv(processed_path + 'test_14d_30_consider_user.csv', sep='\\t')\n",
    "print(test_df_30.shape)\n",
    "test_df_30.rename(columns={\"City\": \"JobCity\", \"State\": \"JobState\", \"Country\": \"JobCountry\"}, inplace = True)\n",
    "test_df_30['JobID_encoded'] = transform_categorical_column(test_df_30['JobID'], job_features_encoders_30['JobID'])\n",
    "test_df_30['JobCity_encoded'] = transform_categorical_column(test_df_30['JobCity'], job_features_encoders_30['JobCity'])\n",
    "test_df_30['JobState_encoded'] = transform_categorical_column(test_df_30['JobState'], job_features_encoders_30['JobState'])\n",
    "test_df_30['JobCountry_encoded'] = transform_categorical_column(test_df_30['JobCountry'], job_features_encoders_30['JobCountry'])\n",
    "print(test_df_30.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f47b5a6-4c6d-4932-8eb0-e664933fa15e",
   "metadata": {},
   "source": [
    "# Step 4: Add user infor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5adeea32-2478-482d-a2fb-b8fb9bb6b4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_new_30 = pd.merge(train_df_30, user_df_30, on='UserID')\n",
    "test_df_new_30 = pd.merge(test_df_30, user_df_30, on='UserID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e964801-4517-4de9-90c5-f64452dcb416",
   "metadata": {},
   "source": [
    "# Step 5: Prepare sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "017c3020-6e86-45c5-b02c-d9ff8b2c033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_session(data_df):\n",
    "    sessions = []\n",
    "    for session_id, rows in data_df.groupby('SessionID'):\n",
    "        clicks = []\n",
    "        for idx, row in rows.iterrows():\n",
    "            click = {'JobID_encoded': row['JobID_encoded'],\n",
    "                     'ApplicationDate': row['ApplicationDate'],\n",
    "                     'WindowID': row['WindowID_x'],\n",
    "                     'JobCity_encoded': row['JobCity_encoded'],\n",
    "                     'JobState_encoded': row['JobState_encoded'],\n",
    "                     'JobCountry_encoded': row['JobCountry_encoded'],\n",
    "                     'UserID_encoded': row['UserID_encoded'],\n",
    "                     'UserCity_encoded': row['UserCity_encoded'],\n",
    "                     'UserState_encoded': row['UserState_encoded'],\n",
    "                     'UserCountry_encoded': row['UserCountry_encoded'],\n",
    "                     'UserDegree_encoded': row['UserDegree_encoded'],\n",
    "                     'UserMajor_encoded': row['UserMajor_encoded']\n",
    "                    }\n",
    "            clicks.append(click)\n",
    "        \n",
    "        session_dict = {'SessionID': session_id,\n",
    "                        'WindowID': rows['WindowID_x'].unique()[0],\n",
    "                        'SessionSize': len(rows),\n",
    "                        'SessionStart': rows['StartDate'].unique()[0],\n",
    "                        'UserID_encoded': rows['UserID_encoded'].unique()[0],\n",
    "                        'Clicks': clicks \n",
    "                       }\n",
    "        sessions.append(session_dict)\n",
    "    #return list(zip(map(lambda x: x['SessionID'], sessions), sessions))\n",
    "    return sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8056fce9-3689-46a7-9e12-1be2941053d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153268\n",
      "11759\n"
     ]
    }
   ],
   "source": [
    "sessions_train_30 =  prepare_session(train_df_new_30)\n",
    "sessions_test_30 =  prepare_session(test_df_new_30)\n",
    "print(len(sessions_train_30))\n",
    "print(len(sessions_test_30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422d4ba2-4bd7-4eac-94a3-35e37a6332a7",
   "metadata": {},
   "source": [
    "# Step 6: Exporting sessions to JSON lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f41b09b4-8806-4b80-aa03-1a538d384c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(NpEncoder, self).default(obj)     \n",
    "\n",
    "def write_list_to_json(list_data, json_path):\n",
    "    with open(json_path, 'w') as  f:\n",
    "        json.dump(list_data, f, cls=NpEncoder)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85ecfeec-2e9c-45ef-a77f-2f6117412fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_list_to_json(sessions_train_30, \"../data/cb12/sessions_json/train_14d_30_sessions\")\n",
    "write_list_to_json(sessions_test_30, \"../data/cb12/sessions_json/test_14d_30_sessions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.7",
   "language": "python",
   "name": "py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
